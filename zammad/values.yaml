image:
  repository: zammad/zammad-docker-compose
  tag: 4.1.0-31
  pullPolicy: IfNotPresent
  imagePullSecrets: []
    # - name: "image-pull-secret"

service:
  type: ClusterIP
  port: 8080

ingress:
  enabled: false
  className: ""
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

secrets:
  autowizard:
    useExisting: false
    secretKey: autowizard
    secretName: autowizard
    # see autowizard.config for secret value
  elasticsearch:
    useExisting: false
    secretKey: password
    secretName: elastic-credentials
    # see envConfig.elasticsearch.pass for secret value
  postgresql:
    useExisting: false
    secretKey: postgresql-pass
    secretName: postgresql-pass
    # see envConfig.postgresql.pass for secret value

# zammad container config
envConfig:
  elasticsearch:
    # host env var is only used when elasticsearch.enabled is false
    host: zammad-master
    pass: ""
    port: 9200
    reindex: true
    schema: http
    user: ""
  memcached:
    # host env var is only used when memcached.enabled is false
    host: zammad-memcached
    port: 11211
  postgresql:
    # needs to be the same as the postgresql.postgresqlPassword
    db: zammad_production
    # host env var is only used when postgresql.enabled is false
    host: zammad-postgresql
    pass: "zammad"
    # needs to be the same as the postgresql.postgresqlDatabase
    port: 5432
    # needs to be the same as the postgresql.postgresqlUsername
    user: zammad
  zammad:
    rails:
      livenessProbe: true
      readinessProbe: true
      trustedProxies: "['127.0.0.1', '::1']"
    nginx:
      extraHeaders: []
        # - 'HeaderName "Header Value"'
      livenessProbe: true
      readinessProbe: true
      websocketExtraHeaders: []
        # - 'HeaderName "Header Value"'
    websocket:
      livenessProbe: true
      readinessProbe: true

# additional environment vars
extraEnv: {}
  # MY_VAR: "foobar"

# autowizard config
# if a token is used the url hast to look like: http://zammad/#getting_started/auto_wizard/your_token_here
autoWizard:
  enabled: false
  # string with the autowizard config as json
  # config: |
  #   {
  #     "Token": "secret_zammad_autowizard_token",
  #     "TextModuleLocale": {
  #       "Locale": "en-us"
  #     },
  #     "Users": [
  #       {
  #         "login": "email@example.org",
  #         "firstname": "Zammad",
  #         "lastname": "Admin",
  #         "email": "email@example.org",
  #         "organization": "ZammadTest",
  #         "password": "YourPassword"
  #       }
  #     ],
  #     "Settings": [
  #       {
  #         "name": "product_name",
  #         "value": "ZammadTestSystem"
  #       },
  #       {
  #         "name": "system_online_service",
  #         "value": true
  #       }
  #     ],
  #     "Organizations": [
  #       {
  #         "name": "ZammadTest"
  #       }
  #     ]
  #   }

podAnnotations: {}
  # my-annotation: "value"

volumePermissions:
  enabled: false
  image:
    repository: alpine
    tag: '3.14'
    pullPolicy: IfNotPresent
persistence:
  enabled: true
  ## A manually managed Persistent Volume and Claim
  ## If defined, PVC must be created manually before volume will be bound
  ## The value is evaluated as a template, so, for example, the name can depend on .Release or .Chart
  ##
  # existingClaim:
  accessModes:
    - ReadWriteOnce
  storageClass: ""
  size: 15Gi
  annotations: {}

# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
resources:
  nginx: {}
    # requests:
    #   cpu: 50m
    #   memory: 32Mi
    # limits:
    #   cpu: 100m
    #   memory: 64Mi
  railsserver: {}
    # requests:
    #   cpu: 100m
    #   memory: 512Mi
    # limits:
    #   cpu: 200m
    #   memory: 1024Mi
  scheduler: {}
    # requests:
    #   cpu: 100m
    #   memory: 256Mi
    # limits:
    #   cpu: 200m
    #   memory: 512Mi
  websocket: {}
    # requests:
    #   cpu: 100m
    #   memory: 256Mi
    # limits:
    #   cpu: 200m
    #   memory: 512Mi

nodeSelector: {}

tolerations: []

affinity: {}


elasticsearch:
  # enable / disable elasticsearch chart dependency
  enabled: true
  # enable / disable zammad specific elasticsearch initialisation - disable this to run zammad without elasticsearch
  enableInitialisation: true
  image: "zammad/zammad-docker-compose"
  imageTag: "zammad-elasticsearch-4.1.0-31"
  clusterName: zammad
  replicas: 1
  # Workaround to get helm test to work in GitHub action CI
  # the [ES chart](https://github.com/elastic/helm-charts/tree/master/elasticsearch) default would be: "wait_for_status=green&timeout=1s"
  # see: <https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster-health.html#request-params>
  clusterHealthCheckParams: "timeout=1s"
  resources: {}
    # requests:
    #   cpu: "100m"
    #   memory: "2Gi"
    # limits:
    #   cpu: "1000m"
    #   memory: "2Gi"
  initResources: {}
    # limits:
    #   cpu: "25m"
    #   # memory: "128Mi"
    # requests:
    #   cpu: "25m"
    #   memory: "128Mi"
  sidecarResources: {}
    # limits:
    #   cpu: "25m"
    #   # memory: "128Mi"
    # requests:
    #   cpu: "25m"
    #   memory: "128Mi"

memcached:
  enabled: true
  replicaCount: 1
  # resources:
  #   requests:
  #     cpu: 50m
  #     memory: 64Mi
  #   limits:
  #     cpu: 100m
  #     memory: 128Mi

postgresql:
  enabled: true
  postgresqlUsername: zammad
  postgresqlPassword: zammad
  postgresqlDatabase: zammad_production
  # resources:
  #   requests:
  #     cpu: 250m
  #     memory: 256Mi
  #   limits:
  #     cpu: 500m
  #     memory: 512Mi

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

rbac:
  # Control whether RBAC resources are created
  create: false

# Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
podSecurityPolicy:
  enabled: false
  # Create PSP
  create: false
  # Annotations to add to PSP. Only applicable if create is true
  annotations: {}
  # The name of the PSP to use. Only applicable if create is false
  name: ""
